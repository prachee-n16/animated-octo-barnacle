{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (160, 160)\n",
    "output_shape = 512\n",
    "\n",
    "def scaling(x, scale):\n",
    "    return x * scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight download link:\"https://github.com/serengil/deepface_models/releases/download/v1.0/facenet512_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionResNetV1(dimension: int = 128) -> Model:\n",
    "    \"\"\"\n",
    "    InceptionResNetV1 model heavily inspired from\n",
    "    github.com/davidsandberg/facenet/blob/master/src/models/inception_resnet_v1.py\n",
    "    As mentioned in Sandberg's repo's readme, pre-trained models are using Inception ResNet v1\n",
    "    Besides training process is documented at\n",
    "    sefiks.com/2018/09/03/face-recognition-with-facenet-in-keras/\n",
    "\n",
    "    Args:\n",
    "        dimension (int): number of dimensions in the embedding layer\n",
    "    Returns:\n",
    "        model (Model)\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = Input(shape=(160, 160, 3))\n",
    "    x = Conv2D(32, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Conv2d_1a_3x3\")(inputs)\n",
    "    x = BatchNormalization(\n",
    "        axis=3, momentum=0.995, epsilon=0.001, scale=False, name=\"Conv2d_1a_3x3_BatchNorm\"\n",
    "    )(x)\n",
    "    x = Activation(\"relu\", name=\"Conv2d_1a_3x3_Activation\")(x)\n",
    "    x = Conv2D(32, 3, strides=1, padding=\"valid\", use_bias=False, name=\"Conv2d_2a_3x3\")(x)\n",
    "    x = BatchNormalization(\n",
    "        axis=3, momentum=0.995, epsilon=0.001, scale=False, name=\"Conv2d_2a_3x3_BatchNorm\"\n",
    "    )(x)\n",
    "    x = Activation(\"relu\", name=\"Conv2d_2a_3x3_Activation\")(x)\n",
    "    x = Conv2D(64, 3, strides=1, padding=\"same\", use_bias=False, name=\"Conv2d_2b_3x3\")(x)\n",
    "    x = BatchNormalization(\n",
    "        axis=3, momentum=0.995, epsilon=0.001, scale=False, name=\"Conv2d_2b_3x3_BatchNorm\"\n",
    "    )(x)\n",
    "    x = Activation(\"relu\", name=\"Conv2d_2b_3x3_Activation\")(x)\n",
    "    x = MaxPooling2D(3, strides=2, name=\"MaxPool_3a_3x3\")(x)\n",
    "    x = Conv2D(80, 1, strides=1, padding=\"valid\", use_bias=False, name=\"Conv2d_3b_1x1\")(x)\n",
    "    x = BatchNormalization(\n",
    "        axis=3, momentum=0.995, epsilon=0.001, scale=False, name=\"Conv2d_3b_1x1_BatchNorm\"\n",
    "    )(x)\n",
    "    x = Activation(\"relu\", name=\"Conv2d_3b_1x1_Activation\")(x)\n",
    "    x = Conv2D(192, 3, strides=1, padding=\"valid\", use_bias=False, name=\"Conv2d_4a_3x3\")(x)\n",
    "    x = BatchNormalization(\n",
    "        axis=3, momentum=0.995, epsilon=0.001, scale=False, name=\"Conv2d_4a_3x3_BatchNorm\"\n",
    "    )(x)\n",
    "    x = Activation(\"relu\", name=\"Conv2d_4a_3x3_Activation\")(x)\n",
    "    x = Conv2D(256, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Conv2d_4b_3x3\")(x)\n",
    "    x = BatchNormalization(\n",
    "        axis=3, momentum=0.995, epsilon=0.001, scale=False, name=\"Conv2d_4b_3x3_BatchNorm\"\n",
    "    )(x)\n",
    "    x = Activation(\"relu\", name=\"Conv2d_4b_3x3_Activation\")(x)\n",
    "\n",
    "    # 5x Block35 (Inception-ResNet-A block):\n",
    "    branch_0 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_1_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_1_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block35_1_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_1_Branch_1_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_1_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block35_1_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_1_Branch_1_Conv2d_0b_3x3\"\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_1_Branch_1_Conv2d_0b_3x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block35_1_Branch_1_Conv2d_0b_3x3_Activation\")(branch_1)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_1_Branch_2_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_1_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_1_Branch_2_Conv2d_0a_1x1_Activation\")(branch_2)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_1_Branch_2_Conv2d_0b_3x3\"\n",
    "    )(branch_2)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_1_Branch_2_Conv2d_0b_3x3_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_1_Branch_2_Conv2d_0b_3x3_Activation\")(branch_2)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_1_Branch_2_Conv2d_0c_3x3\"\n",
    "    )(branch_2)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_1_Branch_2_Conv2d_0c_3x3_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_1_Branch_2_Conv2d_0c_3x3_Activation\")(branch_2)\n",
    "    branches = [branch_0, branch_1, branch_2]\n",
    "    mixed = Concatenate(axis=3, name=\"Block35_1_Concatenate\")(branches)\n",
    "    up = Conv2D(256, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block35_1_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.17})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block35_1_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_2_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_2_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block35_2_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_2_Branch_1_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_2_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block35_2_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_2_Branch_1_Conv2d_0b_3x3\"\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_2_Branch_1_Conv2d_0b_3x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block35_2_Branch_1_Conv2d_0b_3x3_Activation\")(branch_1)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_2_Branch_2_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_2_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_2_Branch_2_Conv2d_0a_1x1_Activation\")(branch_2)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_2_Branch_2_Conv2d_0b_3x3\"\n",
    "    )(branch_2)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_2_Branch_2_Conv2d_0b_3x3_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_2_Branch_2_Conv2d_0b_3x3_Activation\")(branch_2)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_2_Branch_2_Conv2d_0c_3x3\"\n",
    "    )(branch_2)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_2_Branch_2_Conv2d_0c_3x3_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_2_Branch_2_Conv2d_0c_3x3_Activation\")(branch_2)\n",
    "    branches = [branch_0, branch_1, branch_2]\n",
    "    mixed = Concatenate(axis=3, name=\"Block35_2_Concatenate\")(branches)\n",
    "    up = Conv2D(256, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block35_2_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.17})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block35_2_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_3_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_3_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block35_3_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_3_Branch_1_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_3_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block35_3_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_3_Branch_1_Conv2d_0b_3x3\"\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_3_Branch_1_Conv2d_0b_3x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block35_3_Branch_1_Conv2d_0b_3x3_Activation\")(branch_1)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_3_Branch_2_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_3_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_3_Branch_2_Conv2d_0a_1x1_Activation\")(branch_2)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_3_Branch_2_Conv2d_0b_3x3\"\n",
    "    )(branch_2)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_3_Branch_2_Conv2d_0b_3x3_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_3_Branch_2_Conv2d_0b_3x3_Activation\")(branch_2)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_3_Branch_2_Conv2d_0c_3x3\"\n",
    "    )(branch_2)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_3_Branch_2_Conv2d_0c_3x3_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_3_Branch_2_Conv2d_0c_3x3_Activation\")(branch_2)\n",
    "    branches = [branch_0, branch_1, branch_2]\n",
    "    mixed = Concatenate(axis=3, name=\"Block35_3_Concatenate\")(branches)\n",
    "    up = Conv2D(256, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block35_3_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.17})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block35_3_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_4_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_4_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block35_4_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_4_Branch_1_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_4_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block35_4_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_4_Branch_1_Conv2d_0b_3x3\"\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_4_Branch_1_Conv2d_0b_3x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block35_4_Branch_1_Conv2d_0b_3x3_Activation\")(branch_1)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_4_Branch_2_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_4_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_4_Branch_2_Conv2d_0a_1x1_Activation\")(branch_2)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_4_Branch_2_Conv2d_0b_3x3\"\n",
    "    )(branch_2)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_4_Branch_2_Conv2d_0b_3x3_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_4_Branch_2_Conv2d_0b_3x3_Activation\")(branch_2)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_4_Branch_2_Conv2d_0c_3x3\"\n",
    "    )(branch_2)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_4_Branch_2_Conv2d_0c_3x3_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_4_Branch_2_Conv2d_0c_3x3_Activation\")(branch_2)\n",
    "    branches = [branch_0, branch_1, branch_2]\n",
    "    mixed = Concatenate(axis=3, name=\"Block35_4_Concatenate\")(branches)\n",
    "    up = Conv2D(256, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block35_4_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.17})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block35_4_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_5_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_5_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block35_5_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_5_Branch_1_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_5_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block35_5_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_5_Branch_1_Conv2d_0b_3x3\"\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_5_Branch_1_Conv2d_0b_3x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block35_5_Branch_1_Conv2d_0b_3x3_Activation\")(branch_1)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_5_Branch_2_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_5_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_5_Branch_2_Conv2d_0a_1x1_Activation\")(branch_2)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_5_Branch_2_Conv2d_0b_3x3\"\n",
    "    )(branch_2)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_5_Branch_2_Conv2d_0b_3x3_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_5_Branch_2_Conv2d_0b_3x3_Activation\")(branch_2)\n",
    "    branch_2 = Conv2D(\n",
    "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_5_Branch_2_Conv2d_0c_3x3\"\n",
    "    )(branch_2)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block35_5_Branch_2_Conv2d_0c_3x3_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Block35_5_Branch_2_Conv2d_0c_3x3_Activation\")(branch_2)\n",
    "    branches = [branch_0, branch_1, branch_2]\n",
    "    mixed = Concatenate(axis=3, name=\"Block35_5_Concatenate\")(branches)\n",
    "    up = Conv2D(256, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block35_5_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.17})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block35_5_Activation\")(x)\n",
    "\n",
    "    # Mixed 6a (Reduction-A block):\n",
    "    branch_0 = Conv2D(\n",
    "        384, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Mixed_6a_Branch_0_Conv2d_1a_3x3\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Mixed_6a_Branch_0_Conv2d_1a_3x3_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Mixed_6a_Branch_0_Conv2d_1a_3x3_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Mixed_6a_Branch_1_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Mixed_6a_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Mixed_6a_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        192, 3, strides=1, padding=\"same\", use_bias=False, name=\"Mixed_6a_Branch_1_Conv2d_0b_3x3\"\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Mixed_6a_Branch_1_Conv2d_0b_3x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Mixed_6a_Branch_1_Conv2d_0b_3x3_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        256, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Mixed_6a_Branch_1_Conv2d_1a_3x3\"\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Mixed_6a_Branch_1_Conv2d_1a_3x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Mixed_6a_Branch_1_Conv2d_1a_3x3_Activation\")(branch_1)\n",
    "    branch_pool = MaxPooling2D(\n",
    "        3, strides=2, padding=\"valid\", name=\"Mixed_6a_Branch_2_MaxPool_1a_3x3\"\n",
    "    )(x)\n",
    "    branches = [branch_0, branch_1, branch_pool]\n",
    "    x = Concatenate(axis=3, name=\"Mixed_6a\")(branches)\n",
    "\n",
    "    # 10x Block17 (Inception-ResNet-B block):\n",
    "    branch_0 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_1_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_1_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block17_1_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_1_Branch_1_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_1_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_1_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [1, 7],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_1_Branch_1_Conv2d_0b_1x7\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_1_Branch_1_Conv2d_0b_1x7_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_1_Branch_1_Conv2d_0b_1x7_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [7, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_1_Branch_1_Conv2d_0c_7x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_1_Branch_1_Conv2d_0c_7x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_1_Branch_1_Conv2d_0c_7x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block17_1_Concatenate\")(branches)\n",
    "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_1_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block17_1_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_2_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_2_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block17_2_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_2_Branch_2_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_2_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_2_Branch_2_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [1, 7],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_2_Branch_2_Conv2d_0b_1x7\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_2_Branch_2_Conv2d_0b_1x7_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_2_Branch_2_Conv2d_0b_1x7_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [7, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_2_Branch_2_Conv2d_0c_7x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_2_Branch_2_Conv2d_0c_7x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_2_Branch_2_Conv2d_0c_7x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block17_2_Concatenate\")(branches)\n",
    "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_2_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block17_2_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_3_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_3_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block17_3_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_3_Branch_3_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_3_Branch_3_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_3_Branch_3_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [1, 7],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_3_Branch_3_Conv2d_0b_1x7\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_3_Branch_3_Conv2d_0b_1x7_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_3_Branch_3_Conv2d_0b_1x7_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [7, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_3_Branch_3_Conv2d_0c_7x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_3_Branch_3_Conv2d_0c_7x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_3_Branch_3_Conv2d_0c_7x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block17_3_Concatenate\")(branches)\n",
    "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_3_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block17_3_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_4_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_4_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block17_4_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_4_Branch_4_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_4_Branch_4_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_4_Branch_4_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [1, 7],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_4_Branch_4_Conv2d_0b_1x7\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_4_Branch_4_Conv2d_0b_1x7_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_4_Branch_4_Conv2d_0b_1x7_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [7, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_4_Branch_4_Conv2d_0c_7x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_4_Branch_4_Conv2d_0c_7x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_4_Branch_4_Conv2d_0c_7x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block17_4_Concatenate\")(branches)\n",
    "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_4_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block17_4_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_5_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_5_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block17_5_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_5_Branch_5_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_5_Branch_5_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_5_Branch_5_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [1, 7],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_5_Branch_5_Conv2d_0b_1x7\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_5_Branch_5_Conv2d_0b_1x7_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_5_Branch_5_Conv2d_0b_1x7_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [7, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_5_Branch_5_Conv2d_0c_7x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_5_Branch_5_Conv2d_0c_7x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_5_Branch_5_Conv2d_0c_7x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block17_5_Concatenate\")(branches)\n",
    "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_5_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block17_5_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_6_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_6_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block17_6_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_6_Branch_6_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_6_Branch_6_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_6_Branch_6_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [1, 7],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_6_Branch_6_Conv2d_0b_1x7\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_6_Branch_6_Conv2d_0b_1x7_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_6_Branch_6_Conv2d_0b_1x7_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [7, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_6_Branch_6_Conv2d_0c_7x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_6_Branch_6_Conv2d_0c_7x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_6_Branch_6_Conv2d_0c_7x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block17_6_Concatenate\")(branches)\n",
    "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_6_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block17_6_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_7_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_7_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block17_7_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_7_Branch_7_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_7_Branch_7_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_7_Branch_7_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [1, 7],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_7_Branch_7_Conv2d_0b_1x7\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_7_Branch_7_Conv2d_0b_1x7_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_7_Branch_7_Conv2d_0b_1x7_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [7, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_7_Branch_7_Conv2d_0c_7x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_7_Branch_7_Conv2d_0c_7x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_7_Branch_7_Conv2d_0c_7x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block17_7_Concatenate\")(branches)\n",
    "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_7_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block17_7_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_8_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_8_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block17_8_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_8_Branch_8_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_8_Branch_8_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_8_Branch_8_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [1, 7],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_8_Branch_8_Conv2d_0b_1x7\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_8_Branch_8_Conv2d_0b_1x7_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_8_Branch_8_Conv2d_0b_1x7_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [7, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_8_Branch_8_Conv2d_0c_7x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_8_Branch_8_Conv2d_0c_7x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_8_Branch_8_Conv2d_0c_7x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block17_8_Concatenate\")(branches)\n",
    "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_8_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block17_8_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_9_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_9_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block17_9_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_9_Branch_9_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_9_Branch_9_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_9_Branch_9_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [1, 7],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_9_Branch_9_Conv2d_0b_1x7\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_9_Branch_9_Conv2d_0b_1x7_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_9_Branch_9_Conv2d_0b_1x7_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [7, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_9_Branch_9_Conv2d_0c_7x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_9_Branch_9_Conv2d_0c_7x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_9_Branch_9_Conv2d_0c_7x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block17_9_Concatenate\")(branches)\n",
    "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_9_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block17_9_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_10_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_10_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block17_10_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_10_Branch_10_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_10_Branch_10_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_10_Branch_10_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [1, 7],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_10_Branch_10_Conv2d_0b_1x7\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_10_Branch_10_Conv2d_0b_1x7_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_10_Branch_10_Conv2d_0b_1x7_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        128,\n",
    "        [7, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block17_10_Branch_10_Conv2d_0c_7x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block17_10_Branch_10_Conv2d_0c_7x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block17_10_Branch_10_Conv2d_0c_7x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block17_10_Concatenate\")(branches)\n",
    "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_10_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block17_10_Activation\")(x)\n",
    "\n",
    "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
    "    branch_0 = Conv2D(\n",
    "        256, 1, strides=1, padding=\"same\", use_bias=False, name=\"Mixed_7a_Branch_0_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Mixed_7a_Branch_0_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Mixed_7a_Branch_0_Conv2d_0a_1x1_Activation\")(branch_0)\n",
    "    branch_0 = Conv2D(\n",
    "        384, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Mixed_7a_Branch_0_Conv2d_1a_3x3\"\n",
    "    )(branch_0)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Mixed_7a_Branch_0_Conv2d_1a_3x3_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Mixed_7a_Branch_0_Conv2d_1a_3x3_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        256, 1, strides=1, padding=\"same\", use_bias=False, name=\"Mixed_7a_Branch_1_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Mixed_7a_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Mixed_7a_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        256, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Mixed_7a_Branch_1_Conv2d_1a_3x3\"\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Mixed_7a_Branch_1_Conv2d_1a_3x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Mixed_7a_Branch_1_Conv2d_1a_3x3_Activation\")(branch_1)\n",
    "    branch_2 = Conv2D(\n",
    "        256, 1, strides=1, padding=\"same\", use_bias=False, name=\"Mixed_7a_Branch_2_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Mixed_7a_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Mixed_7a_Branch_2_Conv2d_0a_1x1_Activation\")(branch_2)\n",
    "    branch_2 = Conv2D(\n",
    "        256, 3, strides=1, padding=\"same\", use_bias=False, name=\"Mixed_7a_Branch_2_Conv2d_0b_3x3\"\n",
    "    )(branch_2)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Mixed_7a_Branch_2_Conv2d_0b_3x3_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Mixed_7a_Branch_2_Conv2d_0b_3x3_Activation\")(branch_2)\n",
    "    branch_2 = Conv2D(\n",
    "        256, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Mixed_7a_Branch_2_Conv2d_1a_3x3\"\n",
    "    )(branch_2)\n",
    "    branch_2 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Mixed_7a_Branch_2_Conv2d_1a_3x3_BatchNorm\",\n",
    "    )(branch_2)\n",
    "    branch_2 = Activation(\"relu\", name=\"Mixed_7a_Branch_2_Conv2d_1a_3x3_Activation\")(branch_2)\n",
    "    branch_pool = MaxPooling2D(\n",
    "        3, strides=2, padding=\"valid\", name=\"Mixed_7a_Branch_3_MaxPool_1a_3x3\"\n",
    "    )(x)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    x = Concatenate(axis=3, name=\"Mixed_7a\")(branches)\n",
    "\n",
    "    # 5x Block8 (Inception-ResNet-C block):\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_1_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_1_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block8_1_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_1_Branch_1_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_1_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_1_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        192,\n",
    "        [1, 3],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block8_1_Branch_1_Conv2d_0b_1x3\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_1_Branch_1_Conv2d_0b_1x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_1_Branch_1_Conv2d_0b_1x3_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        192,\n",
    "        [3, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block8_1_Branch_1_Conv2d_0c_3x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_1_Branch_1_Conv2d_0c_3x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_1_Branch_1_Conv2d_0c_3x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block8_1_Concatenate\")(branches)\n",
    "    up = Conv2D(1792, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block8_1_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.2})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block8_1_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_2_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_2_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block8_2_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_2_Branch_2_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_2_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_2_Branch_2_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        192,\n",
    "        [1, 3],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block8_2_Branch_2_Conv2d_0b_1x3\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_2_Branch_2_Conv2d_0b_1x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_2_Branch_2_Conv2d_0b_1x3_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        192,\n",
    "        [3, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block8_2_Branch_2_Conv2d_0c_3x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_2_Branch_2_Conv2d_0c_3x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_2_Branch_2_Conv2d_0c_3x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block8_2_Concatenate\")(branches)\n",
    "    up = Conv2D(1792, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block8_2_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.2})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block8_2_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_3_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_3_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block8_3_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_3_Branch_3_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_3_Branch_3_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_3_Branch_3_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        192,\n",
    "        [1, 3],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block8_3_Branch_3_Conv2d_0b_1x3\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_3_Branch_3_Conv2d_0b_1x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_3_Branch_3_Conv2d_0b_1x3_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        192,\n",
    "        [3, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block8_3_Branch_3_Conv2d_0c_3x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_3_Branch_3_Conv2d_0c_3x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_3_Branch_3_Conv2d_0c_3x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block8_3_Concatenate\")(branches)\n",
    "    up = Conv2D(1792, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block8_3_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.2})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block8_3_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_4_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_4_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block8_4_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_4_Branch_4_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_4_Branch_4_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_4_Branch_4_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        192,\n",
    "        [1, 3],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block8_4_Branch_4_Conv2d_0b_1x3\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_4_Branch_4_Conv2d_0b_1x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_4_Branch_4_Conv2d_0b_1x3_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        192,\n",
    "        [3, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block8_4_Branch_4_Conv2d_0c_3x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_4_Branch_4_Conv2d_0c_3x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_4_Branch_4_Conv2d_0c_3x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block8_4_Concatenate\")(branches)\n",
    "    up = Conv2D(1792, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block8_4_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.2})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block8_4_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_5_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_5_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block8_5_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_5_Branch_5_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_5_Branch_5_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_5_Branch_5_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        192,\n",
    "        [1, 3],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block8_5_Branch_5_Conv2d_0b_1x3\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_5_Branch_5_Conv2d_0b_1x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_5_Branch_5_Conv2d_0b_1x3_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        192,\n",
    "        [3, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block8_5_Branch_5_Conv2d_0c_3x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_5_Branch_5_Conv2d_0c_3x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_5_Branch_5_Conv2d_0c_3x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block8_5_Concatenate\")(branches)\n",
    "    up = Conv2D(1792, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block8_5_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.2})(up)\n",
    "    x = add([x, up])\n",
    "    x = Activation(\"relu\", name=\"Block8_5_Activation\")(x)\n",
    "\n",
    "    branch_0 = Conv2D(\n",
    "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_6_Branch_0_Conv2d_1x1\"\n",
    "    )(x)\n",
    "    branch_0 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_6_Branch_0_Conv2d_1x1_BatchNorm\",\n",
    "    )(branch_0)\n",
    "    branch_0 = Activation(\"relu\", name=\"Block8_6_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
    "    branch_1 = Conv2D(\n",
    "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_6_Branch_1_Conv2d_0a_1x1\"\n",
    "    )(x)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_6_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_6_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        192,\n",
    "        [1, 3],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block8_6_Branch_1_Conv2d_0b_1x3\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_6_Branch_1_Conv2d_0b_1x3_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_6_Branch_1_Conv2d_0b_1x3_Activation\")(branch_1)\n",
    "    branch_1 = Conv2D(\n",
    "        192,\n",
    "        [3, 1],\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"Block8_6_Branch_1_Conv2d_0c_3x1\",\n",
    "    )(branch_1)\n",
    "    branch_1 = BatchNormalization(\n",
    "        axis=3,\n",
    "        momentum=0.995,\n",
    "        epsilon=0.001,\n",
    "        scale=False,\n",
    "        name=\"Block8_6_Branch_1_Conv2d_0c_3x1_BatchNorm\",\n",
    "    )(branch_1)\n",
    "    branch_1 = Activation(\"relu\", name=\"Block8_6_Branch_1_Conv2d_0c_3x1_Activation\")(branch_1)\n",
    "    branches = [branch_0, branch_1]\n",
    "    mixed = Concatenate(axis=3, name=\"Block8_6_Concatenate\")(branches)\n",
    "    up = Conv2D(1792, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block8_6_Conv2d_1x1\")(\n",
    "        mixed\n",
    "    )\n",
    "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 1})(up)\n",
    "    x = add([x, up])\n",
    "\n",
    "    # Classification block\n",
    "    x = GlobalAveragePooling2D(name=\"AvgPool\")(x)\n",
    "    x = Dropout(1.0 - 0.8, name=\"Dropout\")(x)\n",
    "    # Bottleneck\n",
    "    x = Dense(dimension, use_bias=False, name=\"Bottleneck\")(x)\n",
    "    x = BatchNormalization(momentum=0.995, epsilon=0.001, scale=False, name=\"Bottleneck_BatchNorm\")(\n",
    "        x\n",
    "    )\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs, x, name=\"inception_resnet_v1\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_facenet512d_model() -> Model:\n",
    "    \"\"\"\n",
    "    Construct FaceNet-512d model, download its weights and load\n",
    "    Returns:\n",
    "        model (Model)\n",
    "    \"\"\"\n",
    "\n",
    "    model = InceptionResNetV1(dimension=512)\n",
    "\n",
    "    weight_file = \"facenet512_weights.h5\"\n",
    "    model.load_weights(weight_file)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_facenet512d_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyu/mambaforge/envs/memora/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"facenet512.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "new_model =load_model(\"facenet512.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
